{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNqYkF5mqDNEu4qk4No4Q3X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":19,"metadata":{"id":"6SJFnw4lat6t","executionInfo":{"status":"ok","timestamp":1664319439948,"user_tz":300,"elapsed":116,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}}},"outputs":[],"source":["import os\n","import sys\n","import requests\n","import re\n","import pickle\n","import json\n","\n","import numpy as np\n","import torch\n","torch.cuda.empty_cache()\n","from tqdm.notebook import tqdm as bar\n","import pathlib"]},{"cell_type":"code","source":["# !pip install transformers\n","# !pip install datasets\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n","from datasets import Dataset, DatasetDict"],"metadata":{"id":"BWO389ZucrKj","executionInfo":{"status":"ok","timestamp":1664319440805,"user_tz":300,"elapsed":150,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["COLAB = True\n","\n","USE_CUDA = False\n","if COLAB:\n","    from google.colab import drive \n","    drive.mount('/content/gdrive')\n","    PATH = 'gdrive/MyDrive/lyricGenerator/'\n","    sys.path.append('gdrive/MyDrive/lyricGenerator/')\n","\n","    USE_CUDA = torch.cuda.is_available()\n","\n","    if USE_CUDA:\n","        DEVICE = torch.device('cuda')\n","        print(\"Using cuda.\")\n","    else:\n","        DEVICE = torch.device('cpu')\n","        print(\"Using cpu.\")\n","\n","    os.chdir(os.path.join(os.getcwd(),'gdrive/MyDrive/lyricGenerator'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"DBQJCcwBaw8Q","executionInfo":{"status":"error","timestamp":1664319037101,"user_tz":300,"elapsed":753,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}},"outputId":"d5119cb9-4772-4855-f9ce-6e16654758cd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Using cuda.\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f944fc642495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using cpu.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gdrive/MyDrive/lyricGenerator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/lyricGenerator/gdrive/MyDrive/lyricGenerator'"]}]},{"cell_type":"code","source":["def get_datasets(artist_name):\n","    if artist_name.find(' ') > -1:\n","        artist_name = '-'.join(artist_name.lower().split(' '))\n","    ds_file = f'./models/{artist_name}/datasets.p'\n","    if os.path.exists(ds_file):\n","        with open(ds_file, 'rb') as handle:\n","            dataset = pickle.load(handle)\n","        return dataset, os.getcwd() + f'/models/{artist_name}'\n","    else:\n","        print(\"Cant find data associated with this artist! Please try again!\")\n","        return None, None\n"],"metadata":{"id":"QHj4NiIxa03Q","executionInfo":{"status":"ok","timestamp":1664321582329,"user_tz":300,"elapsed":174,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["lm_datasets, artist_folder = get_datasets('The National')\n","model_name = artist_folder[artist_folder.rfind('/') + 1:]"],"metadata":{"id":"uFm-_R2BbJww","executionInfo":{"status":"ok","timestamp":1664321609924,"user_tz":300,"elapsed":561,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["trainer_state_path = f'{artist_folder}/output/trainer_state.json'\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\", cache_dir=pathlib.Path('cache').resolve())\n","\n","EPOCHS = 5\n","num_train_epochs = EPOCHS\n","if os.path.isfile(trainer_state_path):\n","  f = open (trainer_state_path, \"r\")\n","  trainer_state = json.loads(f.read()) \n","  f.close()\n","  epoch = trainer_state['epoch']\n","  num_train_epochs += epoch\n","\n","  model = AutoModelForCausalLM.from_pretrained(f'{artist_folder}/output')\n"],"metadata":{"id":"R-qq1oTabjWm","executionInfo":{"status":"ok","timestamp":1664321620552,"user_tz":300,"elapsed":9052,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"08571f95-02ee-462a-9182-ab66a026fc05"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/6c0e6080953db56375760c0471a8c5f2929baf11/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/6c0e6080953db56375760c0471a8c5f2929baf11/vocab.json\n","loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/6c0e6080953db56375760c0471a8c5f2929baf11/merges.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/6c0e6080953db56375760c0471a8c5f2929baf11/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/6c0e6080953db56375760c0471a8c5f2929baf11/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading configuration file config.json from cache at /content/gdrive/MyDrive/lyricGenerator/cache/models--gpt2/snapshots/6c0e6080953db56375760c0471a8c5f2929baf11/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.22.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file pytorch_model.bin from cache at /content/gdrive/MyDrive/lyricGenerator/cache/models--gpt2/snapshots/6c0e6080953db56375760c0471a8c5f2929baf11/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["training_args = TrainingArguments(output_dir = artist_folder + '/output',\n","                                  evaluation_strategy = 'epoch',\n","                                  learning_rate=5e-5,\n","                                  weight_decay=0.01,\n","                                  logging_strategy = 'epoch',\n","                                  num_train_epochs=num_train_epochs,\n","                                  save_strategy = 'epoch',\n","                                  save_total_limit=10,\n","                                  load_best_model_at_end=True)\n","\n","trainer = Trainer(\n","    model=model,\n","    # tokenizer=tokenizer,\n","    args=training_args,\n","    train_dataset=lm_datasets[\"train\"],\n","    eval_dataset=lm_datasets[\"valid\"]\n",")\n","\n","from transformers import get_cosine_schedule_with_warmup\n","train_dataloader = trainer.get_train_dataloader()\n","num_train_steps = len(train_dataloader)\n","trainer.create_optimizer_and_scheduler(num_train_steps)\n","trainer.lr_scheduler = get_cosine_schedule_with_warmup(\n","      trainer.optimizer,\n","      num_warmup_steps=0,\n","      num_training_steps=num_train_steps\n",")\n"],"metadata":{"id":"1ItieygUd-Wj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664321622501,"user_tz":300,"elapsed":528,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}},"outputId":"4e5802b6-04b2-4670-997d-976268701240"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["if os.path.isfile(trainer_state_path):\n","  try:\n","    data = trainer.train(resume_from_checkpoint=True)\n","  except:\n","    data = trainer.train()\n","else:\n","  data = trainer.train()\n","print(data)\n","\n","try:\n","  with open(f'{artist_folder}/output/evaluation.txt') as json_file:\n","      evaluation = json.load(json_file)\n","  eval_loss = evaluation['eval_loss']\n","except:\n","  eval_loss = 9999999\n","  \n","evaluation = trainer.evaluate()\n","if evaluation['eval_loss'] < eval_loss:\n","  save_model = True\n","  with open(f'{artist_folder}/output/evaluation.txt', 'w') as outfile:\n","    json.dump(evaluation, outfile)\n","  print(\"Saved evaluation results\")\n","else:\n","  save_model = False\n","\n","trainer.save_model(f'{artist_folder}/output')\n","trainer.save_state()"],"metadata":{"id":"tH5zJAMog-yB","executionInfo":{"status":"ok","timestamp":1664321733137,"user_tz":300,"elapsed":108628,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"64ba9d6d-41a0-47b7-8acb-b00b44e8f9a6"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 185\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 120\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [120/120 01:44, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.634600</td>\n","      <td>2.763496</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.472800</td>\n","      <td>2.733399</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.312900</td>\n","      <td>2.715698</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.266200</td>\n","      <td>2.710329</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.203200</td>\n","      <td>2.724017</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 23\n","  Batch size = 8\n","Saving model checkpoint to /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-24\n","Configuration saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-24/config.json\n","Model weights saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-24/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 23\n","  Batch size = 8\n","Saving model checkpoint to /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-48\n","Configuration saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-48/config.json\n","Model weights saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-48/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 23\n","  Batch size = 8\n","Saving model checkpoint to /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-72\n","Configuration saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-72/config.json\n","Model weights saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-72/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 23\n","  Batch size = 8\n","Saving model checkpoint to /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-96\n","Configuration saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-96/config.json\n","Model weights saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-96/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 23\n","  Batch size = 8\n","Saving model checkpoint to /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-120\n","Configuration saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-120/config.json\n","Model weights saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-120/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/checkpoint-96 (score: 2.710329055786133).\n","***** Running Evaluation *****\n","  Num examples = 23\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["TrainOutput(global_step=120, training_loss=2.377942117055257, metrics={'train_runtime': 105.2428, 'train_samples_per_second': 8.789, 'train_steps_per_second': 1.14, 'total_flos': 120847564800000.0, 'train_loss': 2.377942117055257, 'epoch': 5.0})\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/3 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/gdrive/MyDrive/lyricGenerator/models/the-national/output\n","Configuration saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/config.json\n"]},{"output_type":"stream","name":"stdout","text":["Saved evaluation results\n"]},{"output_type":"stream","name":"stderr","text":["Model weights saved in /content/gdrive/MyDrive/lyricGenerator/models/the-national/output/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["evaluation = trainer.evaluate()\n","evaluation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"id":"zdKdOd0xg5Aa","executionInfo":{"status":"ok","timestamp":1664321737168,"user_tz":300,"elapsed":948,"user":{"displayName":"Kevin Niu","userId":"02942548817218503242"}},"outputId":"f27e0c41-7657-4ec0-fe69-45f5592e2007"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 23\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/3 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 2.710329055786133,\n"," 'eval_runtime': 0.6102,\n"," 'eval_samples_per_second': 37.696,\n"," 'eval_steps_per_second': 4.917,\n"," 'epoch': 5.0}"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"F6eCTQv1ExuU"},"execution_count":null,"outputs":[]}]}