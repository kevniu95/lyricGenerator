{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lyricsgenius import Genius\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"EaFwVotR7TKt9kDiKTnUmjgEciv5vFvoljxqArZ3Sf4pj0BVFEzpTojPqPo7FTFh\"\n",
    "genius = Genius(token)\n",
    "genius.skip_non_songs = True\n",
    "genius.timeout = 10\n",
    "genius.retries = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "def check_artist_path(artist, override = False):\n",
    "    artist_f_id = '-'.join(artist.lower().split(' '))\n",
    "    if os.path.exists(f'./artists/{artist_f_id}.p') and not override:\n",
    "        print(\"Lyrics have already been created for this artist\")\n",
    "        return f'./artists/{artist_f_id}.p'\n",
    "    return None\n",
    "artist_path = check_artist_path('Taylor Swift')\n",
    "\n",
    "# def check_artist_songs(artist):\n",
    "#     artist_f_id = '-'.join(artist.lower().split(' '))\n",
    "#     songs_path = f'./artists/{artist_f_id}_songs.p'\n",
    "#     if os.path.exists(songs_path):\n",
    "#         print(\"Songs have already been collected for this artist. Loading those...\")\n",
    "#         with open(songs_path, 'rb') as handle:\n",
    "#             return pickle.load(handle)\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by Laura Stevenson...\n",
      "\n",
      "Song 1: \"Living Room, NY\"\n",
      "Song 2: \"Jellyfish\"\n",
      "Song 3: \"Torch Song\"\n",
      "Song 4: \"Master of Art\"\n",
      "Song 5: \"Dermatillomania\"\n",
      "\n",
      "Reached user-specified song limit (5).\n",
      "Done. Found 5 songs.\n",
      "173907\n"
     ]
    }
   ],
   "source": [
    "def get_all_songs(artist):\n",
    "    artist_found = genius.search_artist(artist, max_songs = 5)\n",
    "    if artist_found.name.lower() != artist.lower():\n",
    "        print(f\"Please note that the artist requested was {artist}\")\n",
    "        print(f\"However, the artist used to find search results is {artist_found.name}\")\n",
    "        print(f\"If this seems incorrect, please go back to source code and review!\")\n",
    "    model_name = artist_found.url[artist_found.url.rfind('/') + 1:].lower()\n",
    "    print(artist_found.id)\n",
    "    return artist_found, model_name\n",
    "ls = get_all_songs('Laura Stevenson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_songs(artist_found):\n",
    "    song_list = artist_found.songs\n",
    "    print(len(song_list))\n",
    "    artist_found.songs = [song for song in song_list if artist_found.name.lower() in song.primary_artist.name.lower()]\n",
    "    print(len(song_list))\n",
    "    return artist_found\n",
    "# swift2 = limit_songs(swift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def standardize_song_name(name):\n",
    "    a = re.sub(r'\\([^)]*\\)', '', name)\n",
    "    b = re.sub(r'\\[[^)]*\\]', '', a)\n",
    "    return b.strip().lower().replace('\\u200b','')\n",
    "\n",
    "def clean_lyrics(lyrics):\n",
    "    lyrics = re.sub(r'(\\[.*?\\])*', '', lyrics)\n",
    "    lyrics = re.sub('\\n{2}', '\\n', lyrics)  # Gaps between verses\n",
    "    lyrics = re.sub('\\nYou might also like\\n','', lyrics)\n",
    "\n",
    "    # Want to get consistent apostrophes to get consistent treatment of contractions\n",
    "    lyrics = str(lyrics).replace(\"'\", \"’\")\n",
    "    \n",
    "    lyrics = str(lyrics.strip(\"\\n\"))\n",
    "    lyrics = lyrics.replace(\"EmbedShare URLCopyEmbedCopy\", \"\")\n",
    "    lyrics = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", lyrics)\n",
    "    lyrics = re.sub(r'\\d+$', '', lyrics)\n",
    "    lyrics = str(lyrics).lstrip().rstrip()\n",
    "    lyrics = str(lyrics).replace(\"\\n\\n\", \"\\n\")\n",
    "    lyrics = str(lyrics).replace(\"\\n\\n\", \"\\n\")\n",
    "    lyrics = re.sub(' +', ' ', lyrics)\n",
    "    lyrics = str(lyrics).replace('\"', \"\")\n",
    "    # lyrics = str(lyrics).replace(\"'\", \"\")\n",
    "    lyrics = str(lyrics).replace(\"*\", \"\")\n",
    "\n",
    "    # Remove text at front of lyrics, claiming this is start of lyrics\n",
    "    lyrics = re.sub('(^[\\s\\S]* Lyrics[\\\\n]*)','', lyrics)\n",
    "    lyrics = re.sub('(^[\\s\\S]* Lyrics\\\\n)','', lyrics)\n",
    "    if 'lyrics' in lyrics[:100].lower():\n",
    "        print(\"Lyrics are not properly cleaned!\")\n",
    "    \n",
    "    # Remove some random symbols that represent spaces\n",
    "    lyrics = re.sub('\\u2005',' ', lyrics)\n",
    "    \n",
    "    # Remove non-lyrics text that sometimes appears in lyrics\n",
    "    lyrics = re.sub('\\d*Embed$', '', lyrics)\n",
    "    lyrics = re.sub('(You might also like$)','', lyrics)\n",
    "    if 'You might also like' in lyrics:\n",
    "        print(\"Check out lyrics here...\")\n",
    "        print(lyrics)\n",
    "        print()\n",
    "    return lyrics\n",
    "    \n",
    "def get_lyrics(artist_found):\n",
    "    newDict = {}\n",
    "    for song in artist_found.songs:\n",
    "        title = standardize_song_name(song.title)\n",
    "        if title not in newDict.keys():\n",
    "            newDict[title] = clean_lyrics(song.lyrics)\n",
    "    return newDict\n",
    "# lyric_dict = get_lyrics(swift2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def write_pickle(artist, lyric_dict):\n",
    "    artist_f_id = '-'.join(artist.lower().split(' '))\n",
    "    with open(f'./artists/{artist_f_id}.p', 'wb') as handle:\n",
    "        pickle.dump(lyric_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_artist_lyrics(artist, override = False):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    -A lyrics dict with\n",
    "        title : lyric \n",
    "      pair for all songs found under the artist\n",
    "    \"\"\"\n",
    "    artist_path = check_artist_path(artist, override = override)\n",
    "    if artist_path and not override:\n",
    "        with open(artist_path, 'rb') as handle:\n",
    "            return pickle.load(handle)\n",
    "    \n",
    "    print(f\"Getting songs for {artist}...\")\n",
    "    artist_found, model_name = get_all_songs(artist)\n",
    "    print(\"Limiting songs...\")\n",
    "    artist_found = limit_songs(artist_found)\n",
    "\n",
    "    print(\"Extracting and cleaning lryics...\")\n",
    "    lyric_dict = get_lyrics(artist_found)\n",
    "\n",
    "    print(\"Writing to pickle\")\n",
    "    write_pickle(artist, (lyric_dict, model_name) )\n",
    "\n",
    "    return lyric_dict, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics have already been created for this artist\n"
     ]
    }
   ],
   "source": [
    "ls_lyrics, model_name = get_and_save_artist_lyrics('Laura Stevenson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "\n",
    "def create_prelim_dataset(lyric_dict):\n",
    "    lyrics = [v for k, v in lyric_dict.items()]\n",
    "\n",
    "    my_dataset = Dataset.from_dict({'text' : lyrics})\n",
    "    currLen = len(my_dataset)\n",
    "\n",
    "    train_percentage = 0.85\n",
    "    validation_percentage = 0.15\n",
    "    test_percentage = 00\n",
    "\n",
    "    train, valid , test = np.split(lyrics, [int(currLen*train_percentage), int(currLen*(train_percentage + validation_percentage))])\n",
    "\n",
    "    datasets = DatasetDict(\n",
    "                {\n",
    "                    'train' : Dataset.from_dict({'text': train }),\n",
    "                    'valid' : Dataset.from_dict({'text' : valid}),\n",
    "                    'test' : Dataset.from_dict({'text' : test})\n",
    "                })\n",
    "    return datasets\n",
    "\n",
    "ls_datasets = create_prelim_dataset(ls_lyrics)\n",
    "# ls_datasets['train'][0]\n",
    "# ls_datasets['train'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datasets(ls_datasets, model_name):\n",
    "    folder_path = f'./models/{model_name}'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    new_file = folder_path + '/' + 'datasets.p'\n",
    "\n",
    "    with open(new_file, 'wb') as handle:\n",
    "        pickle.dump(ls_datasets, handle)\n",
    "    return\n",
    "\n",
    "save_datasets(ls_datasets, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'laura-stevenson'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", cache_dir=pathlib.Path('cache').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <meta charset=\"UTF-8\">\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n    <title>Genius</title>\\n    <style>*{box-sizing:border-box}body{width:100%;margin:0;color:#fff;background:#000;font-family:Helvetica Neue,Arial,Helvetica,Geneva,sans-serif;font-size:20px;font-weight:700}a,a:active,a:focus{color:#3d85c6;text-decoration:none}a:hover{border-bottom:1px dotted}header{background-color:#ffff64;padding:10px;color:#000}header img{height:20px;display:block;margin:0 auto}main{max-width:860px;margin:0 auto}.text{text-align:center}.alert{margin:40px 20px}h1{font-size:7.5rem;text-transform:uppercase;font-weight:700;margin:0}@media screen and (max-width:420px){h1{font-size:3.5rem}}.distractions{margin:3rem auto 0;width:100%;max-width:700px}.iframe-container{width:100%;height:0;padding-top:56.25%;position:relative}.iframe-container iframe{max-width:100%;max-height:100%;position:absolute;top:0;left:0}</style>\\n    <style type=\"text/css\">.cloudflare_content{display:none}</style>\\n    <script type=\"text/javascript\">/* eslint-env browser */\\n/* globals mixpanel */\\n/* eslint-disable no-unused-vars */\\nconst METRICS_URL = \\'https://librato-collector.genius.com/v1/metrics\\';\\n\\nfunction sendToLibrato(body) {\\n  if (navigator.sendBeacon) {\\n    navigator.sendBeacon(\\n      METRICS_URL,\\n      new Blob([JSON.stringify(body)], {type: \\'application/json\\'})\\n    );\\n  } else {\\n    fetch(\\n      METRICS_URL,\\n      {\\n        method: \\'POST\\',\\n        body: JSON.stringify(body),\\n        headers: {\\'Content-Type\\': \\'application/json\\'},\\n      }\\n    );\\n  }\\n}\\n\\nfunction count(name, {source}, extra = {}) {\\n  sendToLibrato({counters: [{name, value: 1, source}]});\\n  mixpanel.track(name, Object.assign({source}, extra));\\n}\\n</script>\\n    <script type=\"text/javascript\">!function(e,a){var t,n,i,l;a.__SV||((window.mixpanel=a)._i=[],a.init=function(e,t,n){function o(e,t){var n=t.split(\".\");2==n.length&&(e=e[n[0]],t=n[1]),e[t]=function(){e.push([t].concat(Array.prototype.slice.call(arguments,0)))}}var p=a;for(void 0!==n?p=a[n]=[]:n=\"mixpanel\",p.people=p.people||[],p.toString=function(e){var t=\"mixpanel\";return\"mixpanel\"!==n&&(t+=\".\"+n),e||(t+=\" (stub)\"),t},p.people.toString=function(){return p.toString(1)+\".people (stub)\"},i=\"disable time_event track track_pageview track_links track_forms track_with_groups add_group set_group remove_group register register_once alias unregister identify name_tag set_config reset opt_in_tracking opt_out_tracking has_opted_in_tracking has_opted_out_tracking clear_opt_in_out_tracking start_batch_senders people.set people.set_once people.unset people.increment people.append people.union people.track_charge people.clear_charges people.delete_user people.remove\".split(\" \"),l=0;l<i.length;l++)o(p,i[l]);var r=\"set set_once union unset remove delete\".split(\" \");p.get_group=function(){function e(e){t[e]=function(){call2_args=arguments,call2=[e].concat(Array.prototype.slice.call(call2_args,0)),p.push([n,call2])}}for(var t={},n=[\"get_group\"].concat(Array.prototype.slice.call(arguments,0)),o=0;o<r.length;o++)e(r[o]);return t},a._i.push([e,t,n])},a.__SV=1.2,(t=e.createElement(\"script\")).type=\"text/javascript\",t.async=!0,t.src=\"undefined\"!=typeof MIXPANEL_CUSTOM_LIB_URL?MIXPANEL_CUSTOM_LIB_URL:\"file:\"===e.location.protocol&&\"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js\".match(/^\\\\/\\\\//)?\"https://cdn.mxpnl.com/libs/mixpanel-2-latest.min.js\":\"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js\",(n=e.getElementsByTagName(\"script\")[0]).parentNode.insertBefore(t,n))}(document,window.mixpanel||[]),mixpanel.init(\"77967c52dc38186cc1aadebdd19e2a82\");</script>\\n    <meta http-equiv=\"refresh\" content=\"35\">\\n  <script>\\n    //<![CDATA[\\n    (function(){\\n      window._cf_chl_opt={\\n        cvId: \"2\",\\n        cType: \"non-interactive\",\\n        cNounce: \"75191\",\\n        cRay: \"750e4483ac84e216\",\\n        cHash: \"cb8425bba2adac3\",\\n        cUPMDTk: \"\\\\/Laura-stevenson-living-room-ny-lyrics?__cf_chl_tk=YzZO_atoQHsXU9gM4v5mypWVxzgsYRst4vowRZpnD5I-1664219090-0-gaNycGzNBtE\",\\n        cFPWv: \"g\",\\n        cTTimeMs: \"1000\",\\n        cRq: {\\n          ru: \"aHR0cHM6Ly9nZW5pdXMuY29tL0xhdXJhLXN0ZXZlbnNvbi1saXZpbmctcm9vbS1ueS1seXJpY3M=\",\\n          ra: \"cHl0aG9uLXJlcXVlc3RzLzIuMjcuMQ==\",\\n          rm: \"R0VU\",\\n          d: \"h4E5I70aAh7Va9KJ+1GxEbRtn2DLTNeK92t0nWyBkl93Axt2lLbIzZPyWNWi3v9aZk9s/BDglYGBt5jsJ9ijImp+hXTwKSL09gPXWma3cQk0tLIgKvLVld/SG7xS5HcYqV/cC/zd3CSQi93dea717/HgS9Y0MTrW1HSDoC1ogytHhau/X4XOy9Outl1sWwfCVA5IkItWI0tVGRCFVOPEkQNpcEEWnzEjqqwmvUqLWCQ+L6+5Z3dwNMli4lyNHr+lSBwl1nXc5hbP8j+JMLqgUPtXJXdj4oC//7JMX3IMxGOPJi01pdIfvVK96EnGKFHsVehiwir+A/5eTqOXvxKh0tOENAnAdduXAMpr+3GFnrFP6q646SgaWUlAMjdMPkdsVjYcrSmxi4xNYWf0YKVLIDbNbHNgxft56pDpUW22YsuDMlo5gBs8nHRMBtF680uEE6a+e7rqsUgr4YtgF9V7XfoZgazZZz9cHvbdhRcE6YCYYYmRLknuadXocDcecqvLIInskbla9+iWd9mz7/cup5RVIssjDSwaCeTZ+vpuLH8u4nSpxqtosgdgj4OOy3/7CnkD9VqA7b8PDzo41QayjQ==\",\\n          t: \"MTY2NDIxOTA5MC41MTUwMDA=\",\\n          m: \"rvIPEuJQ/I3yYL1CSFGoqTwGNbCHyVSUes+/+ORwVBs=\",\\n          i1: \"lFbDs2HeVUSd6kxsjJjFGw==\",\\n          i2: \"Eo5gaqpzGTCAqc0pO+TNhQ==\",\\n          zh: \"CjTVwn9XNZkq0esm2p7N7xf+k6qzISv05qP4sHAkLrw=\",\\n          uh: \"JNy/u1JaDY8l68+s834y37Qd6UIzTJLBzCkJPX4t/ps=\",\\n          hh: \"32aD8UBAl18mYvSTL2321kh0bo8zGh3sVHE1rNoLb3A=\",\\n        }\\n      }\\n      window._cf_chl_enter = function(){window._cf_chl_opt.p=1};\\n    })();\\n    //]]>\\n  </script>\\n  \\n</head>\\n  <body>\\n    <header>\\n      <img src=\"data:image/svg+xml;base64,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\" alt=\"Genius logo\"/>\\n    </header>\\n    <main>\\n      <div class=\"text alert\">\\n        <h1>Scrrrr!!</h1>\\n        <div class=\"dek\">Looks like the site is more popular than we thought! We\\'re going to send you on your way in just a sec.</div>\\n        <div class=\"cloudflare_content\">\\n          <div class=\"cf-browser-verification cf-im-under-attack\">\\n  <noscript>\\n    <h1 data-translate=\"turn_on_js\" style=\"color:#bd2426;\">Please turn JavaScript on and reload the page.</h1>\\n  </noscript>\\n  <div id=\"cf-content\" style=\"display:none\">\\n    \\n    <div id=\"cf-bubbles\">\\n      <div class=\"bubbles\"></div>\\n      <div class=\"bubbles\"></div>\\n      <div class=\"bubbles\"></div>\\n    </div>\\n    <h1><span data-translate=\"checking_browser\">Checking your browser before accessing</span> genius.com.</h1>\\n    \\n    <div id=\"no-cookie-warning\" class=\"cookie-warning\" data-translate=\"turn_on_cookies\" style=\"display:none\">\\n      <p data-translate=\"turn_on_cookies\" style=\"color:#bd2426;\">Please enable Cookies and reload the page.</p>\\n    </div>\\n    <p data-translate=\"process_is_automatic\">This process is automatic. Your browser will redirect to your requested content shortly.</p>\\n    <p data-translate=\"allow_5_secs\" id=\"cf-spinner-allow-5-secs\" >Please allow up to 5 seconds&hellip;</p>\\n    <p data-translate=\"redirecting\" id=\"cf-spinner-redirecting\" style=\"display:none\">Redirecting&hellip;</p>\\n  </div>\\n   \\n  <form id=\"challenge-form\" class=\"challenge-form\" action=\"/Laura-stevenson-living-room-ny-lyrics?__cf_chl_f_tk=YzZO_atoQHsXU9gM4v5mypWVxzgsYRst4vowRZpnD5I-1664219090-0-gaNycGzNBtE\" method=\"POST\" enctype=\"application/x-www-form-urlencoded\">\\n    <input type=\"hidden\" name=\"md\" value=\"0SYo9L0vNSUqeHghpwbQgREvZcbiPrbqY3.g6REq_mk-1664219090-0-AXKZlk7q7G4Zn7ni_-FgKHpgLmA-fupKr-L32l7YZzZL4DFwcShhclR2xqhad4P_U1YVG535r-SvnUiO7fM4bqflfHzCXFvkV3fa5wpct4Kq51T23ftz-vzLlOgKDLhoXXYztcyv5tssfOc2fGZc6061pLQcRjbehLTArnuTMq5MKY4s3pNfFksKQGiENhkUteX6G9-s9aSGfPG-em7R2GnSaKNz3hW6lYhQUu-m6sOtWv0nBk5zeo5RWjgv0V483oz_s_3ckur4ufBdPCX8XEZw6G3raBT21lDYvbaplPSmd7A_UnvqdcL-KNDrITcHNAK2olu-mwXybjq7CHLxv-Ksfp-GgFvAIedqdu4eWXOY1Y64I_FupaK0Yw7nOJtbvO580_Z0NPpkfBpDJpDoJERyr5I-LAOLPoqW2tRh3h2psePZ_Jn57w97iVHBOE2bcXb3Rzm4h2kHFM80BFQjvsrdu45QdTqNqc6ISQjQr_2DGAXL21te85-MrrmEskhnUeDC1V0CKkxuhDMsFGDO7R7w7xjD3QXpDFLbQMgV__UnL_6xzNXsNLgVmhfIz3D8IKEVmL-LjyLSVmNi3Xt87kN6ATzpCRqLPcvPYEXBxVFEQ9EjAK3wwtPvWz7r03zRrvu8Rv1eh1RRHCZvZ9zLgkvbuIA7bPUBIm2AQ3qAyw9FYtNs1WNMB2IG75KuvQbkWw\" />\\n    <input type=\"hidden\" name=\"r\" value=\"_RIIvK4ErCVytP4Wcq9NGWsy8UxOxaTycJepElH5dyA-1664219090-0-AUWk2efSsDoPr/pqw7VQEnmzjnPoiVeOEcZ3zx/YtbwITvPEW4lWqdRdXFae33Ujkf882NGxC/KPpyuPeO3bTFEAIQwqS53tFcYG8WhUxGdKlpbHXYyPSFwXDdlUPr/m2c071buuFIEYdZL9v4NiTKIqUjqPS5rMfoZh7azjH6K9Le0YbVyh/l7A5oKKU41f79oOAeDvirvUOf1iT65lKgFxPj6lLajwC5+1kXqfGo7W7oJaKHo1HXeXPCDV+MjYYBPshCZb6nqzRcoMnIzSA3APCX1OBt5N3dYGKRXFQv7GtlQDMZ26fwPFI1o8IvPWJpIFjxBYy46wt5zwiGzSHNd1SslAJNR24kes9BKAOcz95n2IrTnDyAuEQn77zVpaa8CGxpLpbv5NePNKRldhM5mjDp7cvK1RdJibmmlr6SmOem0qM6qAE1ffBA+rhg5VlQB3y3JJEVvQsFpQblPG2oQAD8z8FLj9qMKrO+9AEi8OGvZpg+ngOwmlnADIPq6+p3JkaEJHvNCMiz4hFT2jDreSO1qAPBJl5sUziUVKmkR5lqUscZU0rcHzfzsWWVACfWLHeNWJ+B/GwwgHjSNo3QDZyVp4YFBsYJgQeWlyLpJeXrgZOS/OPm6njG8yxYNhTBzY08RmmfqGqMsFbs4BxeSjqGjvO3cMXLkPO5N1CwkHUGKQNuPaz9TS+7oXFP8iPQAP0CdJiKYPd2eKUjwhisHQ++TF+SpcKR9N5HOREqiHzelAABCMHHM4lWg35p387XKrHWIJxYN7mXkK57y2G8q0a0jzy4mHc3PVmLDazprcdnj0VWjTO4jlMPVs24uJXQqdBA8wImqX7QyNUtxIVA5y64r8hQ5S46u7YdDQSTfTPFVS1JdCmtVjVmF5PwxXyKBUTvsuG+TAHlwXMg8Ia4dNO0ZMOBE5ierwTGGIT99JOKeqDnfQMITrixY4CXc/ko7r39uE1hMQ2362DOK4MSfq7O65K4elggdygfEC/Mps0dm2SoGzqgNzYBlZSecGc2w1L+hK4r+c9Fry4j/4bb8W6ZYxje1V1IK1YR9gACWXmfrzdwgUuEA/2NBjtC5g+0cDe5ukHiM9ASqgakZYFB8+KUHWSkb2SCvDAQrDy0Mhx2w/6WZF9IouMG4znlibD+r5ggHFTZyMWo1dHg34wIT97FGWKyeqQZiSs3pKvSQ7qXf4rU87ON6meFBXmVSlXe+gFn6V+yZIKIRowBuwodcfkGI9YpBCjWNr/zBp9WXmKnPSD3HKSncuLAfIZa5R9gN6knA2SFp4OX5/y56ebtNAbv1wQcEpi8URmFDd+739GcGKH1PUWyQ7lcOyroInjRmnYbr9qFyOnZRanh4JSgM9SAjy6oJGBnaZJB1E+UPD9SZLmt3W7WY31FrNiR7kNDAFAqDwXVx9I6UDFrnhJf6DSRuRbltu1HQc/QvuDKpS+ETttN/2thkldW8PgVnvlD5lDQ0okG3vZ2bgSF/g6WkZ1g/KbE5ASpb8ycquUgEWDHD8y+g/+MPTsc/wSKrBc9Rxx7pIMqCtZLRhks5LAtGrktzNMJgxKVuKUQsXthVdcqGX9/IVm4kc0naeTYkCu+vtkack8eWBOej11QTxJTBeW47dXgemNacieGxqiUfOG27CO6k1KioB6TZoF2LlcJZ/7FHv07AdebIpKxsCrjw=\"/>\\n  </form>\\n       <script>\\n      //<![CDATA[\\n      (function(){\\n          var a = document.getElementById(\\'cf-content\\');\\n          a.style.display = \\'block\\';\\n          var isIE = /(MSIE|Trident\\\\/|Edge\\\\/)/i.test(window.navigator.userAgent);\\n          var trkjs = isIE ? new Image() : document.createElement(\\'img\\');\\n          trkjs.setAttribute(\"src\", \"/cdn-cgi/images/trace/jsch/js/transparent.gif?ray=750e4483ac84e216\");\\n          trkjs.id = \"trk_jschal_js\";\\n          trkjs.setAttribute(\"alt\", \"\");\\n          document.body.appendChild(trkjs);\\n          var cpo=document.createElement(\\'script\\');\\n          cpo.type=\\'text/javascript\\';\\n          cpo.src = \\'/cdn-cgi/challenge-platform/h/g/orchestrate/jsch/v1?ray=750e4483ac84e216\\';\\n          \\n          window._cf_chl_opt.cOgUHash = location.hash === \\'\\' && location.href.indexOf(\\'#\\') !== -1 ? \\'#\\' : location.hash;\\n          window._cf_chl_opt.cOgUQuery = location.search === \\'\\' && location.href.slice(0, -window._cf_chl_opt.cOgUHash.length).indexOf(\\'?\\') !== -1 ? \\'?\\' : location.search;\\n          if (window._cf_chl_opt.cUPMDTk && window.history && window.history.replaceState) {\\n            var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;\\n            history.replaceState(null, null, \"\\\\/Laura-stevenson-living-room-ny-lyrics?__cf_chl_rt_tk=YzZO_atoQHsXU9gM4v5mypWVxzgsYRst4vowRZpnD5I-1664219090-0-gaNycGzNBtE\" + window._cf_chl_opt.cOgUHash);\\n            cpo.onload = function() {\\n              history.replaceState(null, null, ogU);\\n            };\\n          }\\n          \\n          document.getElementsByTagName(\\'head\\')[0].appendChild(cpo);\\n        }());\\n      //]]>\\n    </script>\\n\\n  \\n  <div id=\"trk_jschal_nojs\" style=\"background-image:url(\\'/cdn-cgi/images/trace/jsch/nojs/transparent.gif?ray=750e4483ac84e216\\')\"> </div>\\n</div>\\n\\n        </div>\\n      </div>\\n      <div class=\"text distractions\">\\n        <p>\\n          <a href=\"https://twitter.com/genius\" class=\"twitter-follow-button\" data-show-count=\"true\" data-size=\"large\" data-dnt=\"true\">Follow @genius</a>\\n          <script>!function(t,e,r){var n,s=t.getElementsByTagName(e)[0],i=/^http:/.test(t.location)?\"http\":\"https\";t.getElementById(r)||((n=t.createElement(e)).id=r,n.src=i+\"://platform.twitter.com/widgets.js\",s.parentNode.insertBefore(n,s))}(document,\"script\",\"twitter-wjs\");</script>\\n        </p>\\n      </div>\\n    </main>\\n    <script type=\"text/javascript\">count(\"cloudflare_error.im_under_attack\",{source:\"cloudflare\"});</script>\\n  </body>\\n</html>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get('https://genius.com/Laura-stevenson-living-room-ny-lyrics').text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def regroup_text(examples, block_size):\n",
    "    combined = {k : list(itertools.chain.from_iterable(examples[k])) for k in examples.keys()}\n",
    "    combined['input_ids']\n",
    "\n",
    "    combined_size = len(combined['input_ids']) // block_size * block_size\n",
    "    test_arr = [i for i in range(combined_size)]\n",
    "    combined_size // block_size\n",
    "\n",
    "    new_dict = {}\n",
    "    for k, v in combined.items():\n",
    "        val = []\n",
    "        for i in range(combined_size // block_size):\n",
    "            val.append(v[i * block_size : i * block_size + block_size])\n",
    "        new_dict[k] = val\n",
    "\n",
    "    new_dict['labels'] = new_dict['input_ids'].copy()\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.40ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 289.76ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 305.44ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.83ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 256.16ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 293.53ba/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'])\n",
    "\n",
    "\n",
    "def create_lm_dataset(prelim_dataset):\n",
    "    int_datasets = prelim_dataset.map(tokenize_function, batched = True, remove_columns = ['text'])\n",
    "    # [tokenizer.decode(i) for i in test['train'][0]['input_ids']]\n",
    "\n",
    "    block_size = int(tokenizer.model_max_length / 4)\n",
    "\n",
    "    regroup_texts_fn = partial(regroup_text, block_size = block_size)\n",
    "\n",
    "    lm_datasets = int_datasets.map(\n",
    "                    regroup_texts_fn,\n",
    "                    batched = True,\n",
    "                    batch_size = 100,\n",
    "                    num_proc = 1\n",
    "    )\n",
    "    return lm_datasets\n",
    "\n",
    "lm_datasets = create_lm_dataset(ls_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "num_train_epochs = 30\n",
    "\n",
    "trainer_state_path = f'{model_name}/trainer_state.json'\n",
    "if os.path.isfile(trainer_state_path):\n",
    "    f = open (trainer_state_path, \"r\")\n",
    "    trainer_state = json.loads(f.read()) \n",
    "    f.close()\n",
    "    epoch = trainer_state['epoch']\n",
    "    num_train_epochs += epoch\n",
    "\n",
    "seed_data = random.randint(0,2**32-1)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f\"output/{model_name}\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1.372e-4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_total_limit=10,\n",
    "    save_strategy='epoch',\n",
    "    save_steps=1,\n",
    "    report_to=None,\n",
    "    seed=seed_data,\n",
    "    logging_steps=5,\n",
    "    do_eval=True,\n",
    "    eval_steps=1,\n",
    "    load_best_model_at_end=True\n",
    "    # disable_tqdm=True\n",
    "    # load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' feel',\n",
       " ' you',\n",
       " ' restless',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' wake',\n",
       " ' up',\n",
       " ' from',\n",
       " ' it',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' see',\n",
       " ' you',\n",
       " ' stare',\n",
       " ' at',\n",
       " ' ceilings',\n",
       " ' until',\n",
       " ' you',\n",
       " ' fall',\n",
       " ' back',\n",
       " ' to',\n",
       " ' sleep',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' feel',\n",
       " ' you',\n",
       " ' restless',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' wake',\n",
       " ' up',\n",
       " ' from',\n",
       " ' it',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' see',\n",
       " ' you',\n",
       " ' stare',\n",
       " ' at',\n",
       " ' ceilings',\n",
       " ' until',\n",
       " ' you',\n",
       " ' fall',\n",
       " ' back',\n",
       " ' to',\n",
       " ' sleep',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'It',\n",
       " '�',\n",
       " '�',\n",
       " 's',\n",
       " ' a',\n",
       " ' little',\n",
       " ' stuff',\n",
       " 'y',\n",
       " ' in',\n",
       " ' here',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' wr',\n",
       " 'ing',\n",
       " ' my',\n",
       " ' hands',\n",
       " ' in',\n",
       " ' open',\n",
       " ' elev',\n",
       " 'ators',\n",
       " '\\n',\n",
       " 'A',\n",
       " ' shaky',\n",
       " ' finger',\n",
       " ',',\n",
       " ' I',\n",
       " ' am',\n",
       " ' pushing',\n",
       " ' the',\n",
       " ' door',\n",
       " ' open',\n",
       " ' button',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' feel',\n",
       " ' the',\n",
       " ' urge',\n",
       " ' to',\n",
       " ' press',\n",
       " ' against',\n",
       " ' my',\n",
       " ' neighbors',\n",
       " ' while',\n",
       " ' I',\n",
       " ' keep',\n",
       " ' you',\n",
       " ' in',\n",
       " ' my',\n",
       " ' mind',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' keep',\n",
       " ' you',\n",
       " ' in',\n",
       " ' my',\n",
       " ' mind',\n",
       " ' all',\n",
       " ' of',\n",
       " ' the',\n",
       " ' time',\n",
       " ' here',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'One',\n",
       " ' is',\n",
       " ' moving',\n",
       " ',',\n",
       " ' one',\n",
       " ' is',\n",
       " ' standing',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'In',\n",
       " ' the',\n",
       " ' waiting',\n",
       " ' room',\n",
       " '\\n',\n",
       " 'Wonder',\n",
       " ' where',\n",
       " ' we',\n",
       " '�',\n",
       " '�',\n",
       " 'll',\n",
       " ' land',\n",
       " '\\n',\n",
       " 'Will',\n",
       " ' we',\n",
       " ' fall',\n",
       " ' straight',\n",
       " ' into',\n",
       " ' routine',\n",
       " '?',\n",
       " '\\n',\n",
       " 'Or',\n",
       " ' we',\n",
       " '�',\n",
       " '�',\n",
       " 'll',\n",
       " ' be',\n",
       " ' strangers',\n",
       " ' for',\n",
       " ' a',\n",
       " ' week',\n",
       " ',',\n",
       " ' stir',\n",
       " '-',\n",
       " 'crazy',\n",
       " ',',\n",
       " ' lazy',\n",
       " ' until',\n",
       " ' I',\n",
       " ' leave',\n",
       " ' again',\n",
       " '\\n',\n",
       " 'Then',\n",
       " ' I',\n",
       " ' jump',\n",
       " ' out',\n",
       " ' of',\n",
       " ' my',\n",
       " ' skin',\n",
       " ' until',\n",
       " ' you',\n",
       " ' tell',\n",
       " ' me',\n",
       " ' where',\n",
       " ' I',\n",
       " ' am',\n",
       " '\\n',\n",
       " 'Living',\n",
       " ' Room',\n",
       " ',',\n",
       " ' New',\n",
       " ' York',\n",
       " '\\n',\n",
       " 'Living',\n",
       " ' Room',\n",
       " ',',\n",
       " ' New',\n",
       " ' York',\n",
       " '\\n',\n",
       " 'I',\n",
       " '�',\n",
       " '�',\n",
       " 'll',\n",
       " ' give',\n",
       " ' an',\n",
       " ' arm',\n",
       " ' just',\n",
       " ' to',\n",
       " ' hear',\n",
       " ' you',\n",
       " ' in',\n",
       " ' the',\n",
       " ' dark',\n",
       " ' saying',\n",
       " '\\n',\n",
       " '�',\n",
       " '�',\n",
       " 'Living',\n",
       " ' Room',\n",
       " ',',\n",
       " ' New',\n",
       " ' York',\n",
       " '�',\n",
       " '�',\n",
       " '\\n',\n",
       " 'So',\n",
       " ' I',\n",
       " '�',\n",
       " '�',\n",
       " 'll',\n",
       " ' fold',\n",
       " ' the',\n",
       " ' world',\n",
       " ' to',\n",
       " ' be',\n",
       " ' there',\n",
       " ' tonight',\n",
       " '\\n',\n",
       " '�',\n",
       " '�',\n",
       " 'Cause',\n",
       " ' I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' fall',\n",
       " ' asleep',\n",
       " ' on',\n",
       " ' your',\n",
       " ' time',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' fall',\n",
       " ' asleep',\n",
       " ' where',\n",
       " ' you',\n",
       " ' lie',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' fall',\n",
       " ' asleep',\n",
       " ' with',\n",
       " ' you',\n",
       " ' shifting',\n",
       " ' by',\n",
       " ' my',\n",
       " ' side',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' fall',\n",
       " ' asleep',\n",
       " ' where',\n",
       " ' you',\n",
       " ' lie',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' want',\n",
       " ' to',\n",
       " ' fall',\n",
       " ' asleep',\n",
       " ' with',\n",
       " ' you',\n",
       " ',',\n",
       " ' I',\n",
       " '\\n',\n",
       " 'With',\n",
       " ' you',\n",
       " ',',\n",
       " ' I',\n",
       " '\\n',\n",
       " 'With',\n",
       " ' you',\n",
       " ',',\n",
       " ' I',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' miss',\n",
       " ' you',\n",
       " ',',\n",
       " ' I']"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    # tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I want to feel you restless\\nI want to wake up from it\\nI want to see you stare at ceilings until you fall back to sleep\\nI want to feel you restless\\nI want to wake up from it\\nI want to see you stare at ceilings until you fall back to sleep\\nIn the waiting room\\nIn the waiting room\\nIn the waiting room\\nIt’s a little stuffy in here\\nI want to wring my hands in open elevators\\nA shaky finger, I am pushing the door open button\\nI want to feel the urge to press against my neighbors while I keep you in my mind\\nI keep you in my mind all of the time here\\nIn the waiting room\\nIn the waiting room\\nIn the waiting room\\nOne is moving, one is standing\\nIn the waiting room\\nIn the waiting room\\nIn the waiting room\\nWonder where we’ll land\\nWill we fall straight into routine?\\nOr we’ll be strangers for a week, stir-crazy, lazy until I leave again\\nThen I jump out of my skin until you tell me where I am\\nLiving Room, New York\\nLiving Room, New York\\nI’ll give an arm just to hear you in the dark saying\\n“Living Room, New York”\\nSo I’ll fold the world to be there tonight\\n’Cause I want to fall asleep on your time\\nI want to fall asleep where you lie\\nI want to fall asleep with you shifting by my side\\nI want to fall asleep where you lie\\nI want to fall asleep with you, I\\nWith you, I\\nWith you, I\\nI miss you, I'}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=1, remove_columns=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 193kB/s]\n",
      "Downloading: 100%|██████████| 548M/548M [00:41<00:00, 13.2MB/s] \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name) # np.log(1000)\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "[Errno 403] 403 Client Error: Forbidden for url: https://api.genius.com/songs/https://genius.com/Taylor-swift-all-too-well-10-minute-version-taylors-version-from-the-vault-lyrics?text_format=plain\nAction forbidden for current scope",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_new2/lib/python3.10/site-packages/lyricsgenius/api/base.py:80\u001b[0m, in \u001b[0;36mSender._make_request\u001b[0;34m(self, path, method, params_, public_api, web, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mrequest(method, uri,\n\u001b[1;32m     76\u001b[0m                                      timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout,\n\u001b[1;32m     77\u001b[0m                                      params\u001b[39m=\u001b[39mparams_,\n\u001b[1;32m     78\u001b[0m                                      headers\u001b[39m=\u001b[39mheader,\n\u001b[1;32m     79\u001b[0m                                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 80\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m     81\u001b[0m \u001b[39mexcept\u001b[39;00m Timeout \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_new2/lib/python3.10/site-packages/requests/models.py:960\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m--> 960\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://api.genius.com/songs/https://genius.com/Taylor-swift-all-too-well-10-minute-version-taylors-version-from-the-vault-lyrics?text_format=plain",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kniu91/Documents/Kevin's Folders/Grad Schools/UChicago MPCS/Fall 2022/lyricGenerator/test.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kniu91/Documents/Kevin%27s%20Folders/Grad%20Schools/UChicago%20MPCS/Fall%202022/lyricGenerator/test.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m genius\u001b[39m.\u001b[39;49mlyrics(swift2[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_new2/lib/python3.10/site-packages/lyricsgenius/genius.py:128\u001b[0m, in \u001b[0;36mGenius.lyrics\u001b[0;34m(self, song_id, song_url, remove_section_headers)\u001b[0m\n\u001b[1;32m    126\u001b[0m     path \u001b[39m=\u001b[39m song_url\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mhttps://genius.com/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msong(song_id)[\u001b[39m'\u001b[39m\u001b[39msong\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m:]\n\u001b[1;32m    130\u001b[0m \u001b[39m# Scrape the song lyrics from the HTML\u001b[39;00m\n\u001b[1;32m    131\u001b[0m html \u001b[39m=\u001b[39m BeautifulSoup(\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(path, web\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m<br/>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m),\n\u001b[1;32m    133\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_new2/lib/python3.10/site-packages/lyricsgenius/api/api.py:437\u001b[0m, in \u001b[0;36mAPI.song\u001b[0;34m(self, song_id, text_format)\u001b[0m\n\u001b[1;32m    435\u001b[0m endpoint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msongs/\u001b[39m\u001b[39m{id}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mid\u001b[39m\u001b[39m=\u001b[39msong_id)\n\u001b[1;32m    436\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtext_format\u001b[39m\u001b[39m'\u001b[39m: text_format \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_format}\n\u001b[0;32m--> 437\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(endpoint, params_\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_new2/lib/python3.10/site-packages/lyricsgenius/api/base.py:88\u001b[0m, in \u001b[0;36mSender._make_request\u001b[0;34m(self, path, method, params_, public_api, web, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     error \u001b[39m=\u001b[39m get_description(e)\n\u001b[1;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m500\u001b[39m \u001b[39mor\u001b[39;00m tries \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretries:\n\u001b[0;32m---> 88\u001b[0m         \u001b[39mraise\u001b[39;00m HTTPError(response\u001b[39m.\u001b[39mstatus_code, error)\n\u001b[1;32m     90\u001b[0m \u001b[39m# Enforce rate limiting\u001b[39;00m\n\u001b[1;32m     91\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msleep_time)\n",
      "\u001b[0;31mHTTPError\u001b[0m: [Errno 403] 403 Client Error: Forbidden for url: https://api.genius.com/songs/https://genius.com/Taylor-swift-all-too-well-10-minute-version-taylors-version-from-the-vault-lyrics?text_format=plain\nAction forbidden for current scope"
     ]
    }
   ],
   "source": [
    "genius.lyrics(swift2[0]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all too well\n"
     ]
    }
   ],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919\n",
      "578\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# genius.lyrics(song_url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"All Too Well (10 Minute Version) (Taylor’s Version) [From the Vault]\" by Taylor Swift...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Song(id, artist, ...)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_popular_song = genius.search_song(swiftsongs[0]['title'], 'Taylor Swift')\n",
    "least_popular_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'highlights': [],\n",
       " 'index': 'song',\n",
       " 'type': 'song',\n",
       " 'result': {'annotation_count': 10,\n",
       "  'api_path': '/songs/2885745',\n",
       "  'artist_names': 'Andy Shauf',\n",
       "  'full_title': 'Begin Again by\\xa0Andy\\xa0Shauf',\n",
       "  'header_image_thumbnail_url': 'https://images.genius.com/0d031f033e938b07532758a7e2d6e29f.300x300x1.jpg',\n",
       "  'header_image_url': 'https://images.genius.com/0d031f033e938b07532758a7e2d6e29f.1000x1000x1.jpg',\n",
       "  'id': 2885745,\n",
       "  'language': 'en',\n",
       "  'lyrics_owner_id': 1684296,\n",
       "  'lyrics_state': 'complete',\n",
       "  'path': '/Andy-shauf-begin-again-lyrics',\n",
       "  'pyongs_count': None,\n",
       "  'relationships_index_url': 'https://genius.com/Andy-shauf-begin-again-sample',\n",
       "  'release_date_components': {'year': 2016, 'month': 5, 'day': 20},\n",
       "  'release_date_for_display': 'May 20, 2016',\n",
       "  'song_art_image_thumbnail_url': 'https://images.genius.com/0d031f033e938b07532758a7e2d6e29f.300x300x1.jpg',\n",
       "  'song_art_image_url': 'https://images.genius.com/0d031f033e938b07532758a7e2d6e29f.1000x1000x1.jpg',\n",
       "  'stats': {'unreviewed_annotations': 10, 'hot': False, 'pageviews': 14045},\n",
       "  'title': 'Begin Again',\n",
       "  'title_with_featured': 'Begin Again',\n",
       "  'url': 'https://genius.com/Andy-shauf-begin-again-lyrics',\n",
       "  'featured_artists': [],\n",
       "  'primary_artist': {'api_path': '/artists/380491',\n",
       "   'header_image_url': 'https://images.genius.com/a5f58893498df48fadc615a81e355255.1000x1000x1.jpg',\n",
       "   'id': 380491,\n",
       "   'image_url': 'https://images.genius.com/a5f58893498df48fadc615a81e355255.1000x1000x1.jpg',\n",
       "   'is_meme_verified': False,\n",
       "   'is_verified': False,\n",
       "   'name': 'Andy Shauf',\n",
       "   'url': 'https://genius.com/artists/Andy-shauf'}}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = genius.search_songs('Begin Again Andy Shauf')\n",
    "songs['hits'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_count': 38,\n",
       " 'api_path': '/songs/7076626',\n",
       " 'artist_names': 'Taylor Swift',\n",
       " 'full_title': \"All Too Well (10 Minute Version) (Taylor's Version) [From the Vault] by\\xa0Taylor\\xa0Swift\",\n",
       " 'header_image_thumbnail_url': 'https://images.genius.com/aac8ea3f13ae887a7f1fd9cdd451374e.300x300x1.png',\n",
       " 'header_image_url': 'https://images.genius.com/aac8ea3f13ae887a7f1fd9cdd451374e.1000x1000x1.png',\n",
       " 'id': 7076626,\n",
       " 'language': 'en',\n",
       " 'lyrics_owner_id': 12603744,\n",
       " 'lyrics_state': 'complete',\n",
       " 'path': '/Taylor-swift-all-too-well-10-minute-version-taylors-version-from-the-vault-lyrics',\n",
       " 'pyongs_count': 211,\n",
       " 'relationships_index_url': 'https://genius.com/Taylor-swift-all-too-well-10-minute-version-taylors-version-from-the-vault-sample',\n",
       " 'release_date_components': {'year': 2021, 'month': 11, 'day': 12},\n",
       " 'release_date_for_display': 'November 12, 2021',\n",
       " 'song_art_image_thumbnail_url': 'https://images.genius.com/9dd4ba749dd51d39d7b56b67b9cc3777.300x300x1.jpg',\n",
       " 'song_art_image_url': 'https://images.genius.com/9dd4ba749dd51d39d7b56b67b9cc3777.1000x1000x1.jpg',\n",
       " 'stats': {'unreviewed_annotations': 2,\n",
       "  'concurrents': 2,\n",
       "  'hot': False,\n",
       "  'pageviews': 2969377},\n",
       " 'title': 'All Too Well (10 Minute Version) (Taylor’s Version) [From the Vault]',\n",
       " 'title_with_featured': \"All Too Well (10 Minute Version) (Taylor's Version) [From the Vault]\",\n",
       " 'url': 'https://genius.com/Taylor-swift-all-too-well-10-minute-version-taylors-version-from-the-vault-lyrics',\n",
       " 'featured_artists': [],\n",
       " 'primary_artist': {'api_path': '/artists/1177',\n",
       "  'header_image_url': 'https://images.genius.com/b3ecb764a74b870c7ddb30d7813966df.1000x333x1.jpg',\n",
       "  'id': 1177,\n",
       "  'image_url': 'https://images.genius.com/866d31e6a0fb376d0117018b5913369f.1000x1000x1.png',\n",
       "  'is_meme_verified': True,\n",
       "  'is_verified': True,\n",
       "  'name': 'Taylor Swift',\n",
       "  'url': 'https://genius.com/artists/Taylor-swift',\n",
       "  'iq': 1544}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swift2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp_new2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e08048f17ff008031266911b66a2ac7278627f8d3490a4b4484f3664274d5bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
